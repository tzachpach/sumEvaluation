{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:49:21.106759600Z",
     "start_time": "2023-08-01T16:49:21.098253300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/raid/AICOE/aviv/osint/sumVeracity/summac/summac\n"
     ]
    }
   ],
   "source": [
    "%cd summac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T16:49:28.497112Z",
     "start_time": "2023-08-01T16:49:21.405504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "from summac.benchmark import SummaCBenchmark\n",
    "# import summac.run_baseline as utils_summac_benchmark\n",
    "# import random\n",
    "import transformers\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
    "transformers.utils.logging.set_verbosity(transformers.logging.ERROR)\n",
    "print(transformers.utils.logging.get_verbosity())\n",
    "\n",
    "benchmark = SummaCBenchmark(benchmark_folder=\"data/summac_benchmark/\", cut=\"test\")\n",
    "# benchmark.print_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2: Main Table of Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-03T11:50:54.240245800Z",
     "start_time": "2023-08-03T11:50:53.479222Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.optimization because of the following error (look up to see its traceback):\nDescriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1099\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1098\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1099\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimportlib\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimport_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mmodule_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__name__\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\importlib\\__init__.py:127\u001B[0m, in \u001B[0;36mimport_module\u001B[1;34m(name, package)\u001B[0m\n\u001B[0;32m    126\u001B[0m         level \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m--> 127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_bootstrap\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_gcd_import\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m[\u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpackage\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1030\u001B[0m, in \u001B[0;36m_gcd_import\u001B[1;34m(name, package, level)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1007\u001B[0m, in \u001B[0;36m_find_and_load\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:986\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[1;34m(name, import_)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:680\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[1;34m(spec)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap_external>:850\u001B[0m, in \u001B[0;36mexec_module\u001B[1;34m(self, module)\u001B[0m\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:228\u001B[0m, in \u001B[0;36m_call_with_frames_removed\u001B[1;34m(f, *args, **kwds)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\optimization.py:27\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlr_scheduler\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LambdaLR, ReduceLROnPlateau\n\u001B[1;32m---> 27\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtrainer_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SchedulerType\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m logging\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\trainer_utils.py:48\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_tf_available():\n\u001B[1;32m---> 48\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mtf\u001B[39;00m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mseed_worker\u001B[39m(_):\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\__init__.py:37\u001B[0m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01m_typing\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_util \u001B[38;5;28;01mas\u001B[39;00m _module_util\n\u001B[0;32m     38\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlazy_loader\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LazyLoader \u001B[38;5;28;01mas\u001B[39;00m _LazyLoader\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\__init__.py:37\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pywrap_tensorflow \u001B[38;5;28;01mas\u001B[39;00m _pywrap_tensorflow\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01meager\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m context\n\u001B[0;32m     39\u001B[0m \u001B[38;5;66;03m# pylint: enable=wildcard-import\u001B[39;00m\n\u001B[0;32m     40\u001B[0m \n\u001B[0;32m     41\u001B[0m \u001B[38;5;66;03m# Bring in subpackages.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:29\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msix\u001B[39;00m\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m function_pb2\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mprotobuf\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m config_pb2\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py:16\u001B[0m\n\u001B[0;32m     13\u001B[0m _sym_db \u001B[38;5;241m=\u001B[39m _symbol_database\u001B[38;5;241m.\u001B[39mDefault()\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m attr_value_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m node_def_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_node__def__pb2\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py:16\u001B[0m\n\u001B[0;32m     13\u001B[0m _sym_db \u001B[38;5;241m=\u001B[39m _symbol_database\u001B[38;5;241m.\u001B[39mDefault()\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_tensor__pb2\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_shape_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py:16\u001B[0m\n\u001B[0;32m     13\u001B[0m _sym_db \u001B[38;5;241m=\u001B[39m _symbol_database\u001B[38;5;241m.\u001B[39mDefault()\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m resource_handle_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_shape_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py:16\u001B[0m\n\u001B[0;32m     13\u001B[0m _sym_db \u001B[38;5;241m=\u001B[39m _symbol_database\u001B[38;5;241m.\u001B[39mDefault()\n\u001B[1;32m---> 16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tensor_shape_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mframework\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m types_pb2 \u001B[38;5;28;01mas\u001B[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_shape_pb2.py:36\u001B[0m\n\u001B[0;32m     18\u001B[0m DESCRIPTOR \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mFileDescriptor(\n\u001B[0;32m     19\u001B[0m   name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow/core/framework/tensor_shape.proto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     20\u001B[0m   package\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     23\u001B[0m   serialized_pb\u001B[38;5;241m=\u001B[39m_b(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m,tensorflow/core/framework/tensor_shape.proto\u001B[39m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mtensorflow\u001B[39m\u001B[38;5;130;01m\\\"\u001B[39;00m\u001B[38;5;124mz\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x10\u001B[39;00m\u001B[38;5;124mTensorShapeProto\u001B[39m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;124m-\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x64\u001B[39;00m\u001B[38;5;124mim\u001B[39m\u001B[38;5;130;01m\\x18\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;130;01m\\x0b\u001B[39;00m\u001B[38;5;130;01m\\x32\u001B[39;00m\u001B[38;5;124m .tensorflow.TensorShapeProto.Dim\u001B[39m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x14\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x0c\u001B[39;00m\u001B[38;5;124munknown_rank\u001B[39m\u001B[38;5;130;01m\\x18\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;130;01m\\x08\u001B[39;00m\u001B[38;5;130;01m\\x1a\u001B[39;00m\u001B[38;5;124m!\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x44\u001B[39;00m\u001B[38;5;124mim\u001B[39m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x0c\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;124msize\u001B[39m\u001B[38;5;130;01m\\x18\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;130;01m\\x03\u001B[39;00m\u001B[38;5;130;01m\\x12\u001B[39;00m\u001B[38;5;130;01m\\x0c\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x04\u001B[39;00m\u001B[38;5;124mname\u001B[39m\u001B[38;5;130;01m\\x18\u001B[39;00m\u001B[38;5;130;01m\\x02\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;124m(\u001B[39m\u001B[38;5;130;01m\\t\u001B[39;00m\u001B[38;5;124mB\u001B[39m\u001B[38;5;130;01m\\x87\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;130;01m\\x18\u001B[39;00m\u001B[38;5;124morg.tensorflow.frameworkB\u001B[39m\u001B[38;5;130;01m\\x11\u001B[39;00m\u001B[38;5;124mTensorShapeProtosP\u001B[39m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;124mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001B[39m\u001B[38;5;130;01m\\xf8\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x01\u001B[39;00m\u001B[38;5;130;01m\\x62\u001B[39;00m\u001B[38;5;130;01m\\x06\u001B[39;00m\u001B[38;5;124mproto3\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     24\u001B[0m )\n\u001B[0;32m     29\u001B[0m _TENSORSHAPEPROTO_DIM \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mDescriptor(\n\u001B[0;32m     30\u001B[0m   name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDim\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     31\u001B[0m   full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow.TensorShapeProto.Dim\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     32\u001B[0m   filename\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     33\u001B[0m   file\u001B[38;5;241m=\u001B[39mDESCRIPTOR,\n\u001B[0;32m     34\u001B[0m   containing_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     35\u001B[0m   fields\u001B[38;5;241m=\u001B[39m[\n\u001B[1;32m---> 36\u001B[0m     \u001B[43m_descriptor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mFieldDescriptor\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     37\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msize\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfull_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtensorflow.TensorShapeProto.Dim.size\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     38\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnumber\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mtype\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcpp_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     39\u001B[0m \u001B[43m      \u001B[49m\u001B[43mhas_default_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdefault_value\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmessage_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43menum_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontaining_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     41\u001B[0m \u001B[43m      \u001B[49m\u001B[43mis_extension\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mextension_scope\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     42\u001B[0m \u001B[43m      \u001B[49m\u001B[43mserialized_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfile\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDESCRIPTOR\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m     43\u001B[0m     _descriptor\u001B[38;5;241m.\u001B[39mFieldDescriptor(\n\u001B[0;32m     44\u001B[0m       name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m, full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow.TensorShapeProto.Dim.name\u001B[39m\u001B[38;5;124m'\u001B[39m, index\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     45\u001B[0m       number\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m2\u001B[39m, \u001B[38;5;28mtype\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m9\u001B[39m, cpp_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m9\u001B[39m, label\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m     46\u001B[0m       has_default_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, default_value\u001B[38;5;241m=\u001B[39m_b(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m),\n\u001B[0;32m     47\u001B[0m       message_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, enum_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, containing_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     48\u001B[0m       is_extension\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, extension_scope\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     49\u001B[0m       serialized_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, file\u001B[38;5;241m=\u001B[39mDESCRIPTOR),\n\u001B[0;32m     50\u001B[0m   ],\n\u001B[0;32m     51\u001B[0m   extensions\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m     52\u001B[0m   ],\n\u001B[0;32m     53\u001B[0m   nested_types\u001B[38;5;241m=\u001B[39m[],\n\u001B[0;32m     54\u001B[0m   enum_types\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m     55\u001B[0m   ],\n\u001B[0;32m     56\u001B[0m   serialized_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m     57\u001B[0m   is_extendable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m     58\u001B[0m   syntax\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mproto3\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     59\u001B[0m   extension_ranges\u001B[38;5;241m=\u001B[39m[],\n\u001B[0;32m     60\u001B[0m   oneofs\u001B[38;5;241m=\u001B[39m[\n\u001B[0;32m     61\u001B[0m   ],\n\u001B[0;32m     62\u001B[0m   serialized_start\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m149\u001B[39m,\n\u001B[0;32m     63\u001B[0m   serialized_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m182\u001B[39m,\n\u001B[0;32m     64\u001B[0m )\n\u001B[0;32m     66\u001B[0m _TENSORSHAPEPROTO \u001B[38;5;241m=\u001B[39m _descriptor\u001B[38;5;241m.\u001B[39mDescriptor(\n\u001B[0;32m     67\u001B[0m   name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTensorShapeProto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     68\u001B[0m   full_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtensorflow.TensorShapeProto\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    100\u001B[0m   serialized_end\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m182\u001B[39m,\n\u001B[0;32m    101\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\google\\protobuf\\descriptor.py:561\u001B[0m, in \u001B[0;36mFieldDescriptor.__new__\u001B[1;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001B[0m\n\u001B[0;32m    555\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__new__\u001B[39m(\u001B[38;5;28mcls\u001B[39m, name, full_name, index, number, \u001B[38;5;28mtype\u001B[39m, cpp_type, label,\n\u001B[0;32m    556\u001B[0m             default_value, message_type, enum_type, containing_type,\n\u001B[0;32m    557\u001B[0m             is_extension, extension_scope, options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    558\u001B[0m             serialized_options\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    559\u001B[0m             has_default_value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, containing_oneof\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, json_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m    560\u001B[0m             file\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, create_key\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):  \u001B[38;5;66;03m# pylint: disable=redefined-builtin\u001B[39;00m\n\u001B[1;32m--> 561\u001B[0m   \u001B[43m_message\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMessage\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_CheckCalledFromGeneratedFile\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    562\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m is_extension:\n",
      "\u001B[1;31mTypeError\u001B[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[8], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mseaborn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msns\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# from summac.model_guardrails import NERInaccuracyPenalty\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msummac\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel_summac\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SummaCZS \u001B[38;5;66;03m# SummaCConv\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# from summac.model_baseline import BaselineScorer\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# from model_entailment import EntailmentScorer\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# from model_classifier import Classifier\u001B[39;00m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msummac\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils_scoring\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ScorerWrapper\n",
      "File \u001B[1;32m~\\PycharmProjects\\sumVeracity\\summac\\summac\\model_summac.py:5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnltk\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mos\u001B[39;00m\u001B[38;5;241m,\u001B[39m \u001B[38;5;21;01mjson\u001B[39;00m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msummac\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils_misc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m batcher\n\u001B[1;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mblanc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BlancHelp\n\u001B[0;32m      7\u001B[0m nltk\u001B[38;5;241m.\u001B[39mdownload(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpunkt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      9\u001B[0m model_map \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m     10\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msnli-base\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_card\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboychaboy/SNLI_roberta-base\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentailment_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontradiction_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m},\n\u001B[0;32m     11\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msnli-large\u001B[39m\u001B[38;5;124m\"\u001B[39m: {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodel_card\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mboychaboy/SNLI_roberta-large\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentailment_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcontradiction_idx\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m},\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;66;03m# \"decomp\": 0,\u001B[39;00m\n\u001B[0;32m     20\u001B[0m }\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\blanc\\__init__.py:2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m__version__\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__\n\u001B[1;32m----> 2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mblanc\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BlancHelp, BlancTune\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mestime\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Estime\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mshannon\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Shannon\n",
      "File \u001B[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\blanc\\blanc.py:11\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pad_sequence\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m\n\u001B[1;32m---> 11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BertForMaskedLM, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AlbertForMaskedLM, AlbertTokenizer\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mblanc\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[0;32m     15\u001B[0m     BertInput,\n\u001B[0;32m     16\u001B[0m     Defaults,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     32\u001B[0m     TOKEN_REPLACE_RANGE,\n\u001B[0;32m     33\u001B[0m )\n",
      "File \u001B[1;32m<frozen importlib._bootstrap>:1055\u001B[0m, in \u001B[0;36m_handle_fromlist\u001B[1;34m(module, fromlist, import_, recursive)\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1089\u001B[0m, in \u001B[0;36m_LazyModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1087\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_module(name)\n\u001B[0;32m   1088\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_class_to_module\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[1;32m-> 1089\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_module\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_class_to_module\u001B[49m\u001B[43m[\u001B[49m\u001B[43mname\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1090\u001B[0m     value \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(module, name)\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\transformers\\utils\\import_utils.py:1101\u001B[0m, in \u001B[0;36m_LazyModule._get_module\u001B[1;34m(self, module_name)\u001B[0m\n\u001B[0;32m   1099\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m importlib\u001B[38;5;241m.\u001B[39mimport_module(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m module_name, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m)\n\u001B[0;32m   1100\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m-> 1101\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m   1102\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFailed to import \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodule_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m because of the following error (look up to see its\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1103\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m traceback):\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{\u001B[39;00me\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1104\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01me\u001B[39;00m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Failed to import transformers.optimization because of the following error (look up to see its traceback):\nDescriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "import sklearn, pandas as pd, seaborn as sns\n",
    "# from summac.model_guardrails import NERInaccuracyPenalty\n",
    "from summac.model_summac import SummaCZS # SummaCConv\n",
    "# from summac.model_baseline import BaselineScorer\n",
    "# from model_entailment import EntailmentScorer\n",
    "# from model_classifier import Classifier\n",
    "from summac.utils_scoring import ScorerWrapper\n",
    "\n",
    "use_cache = True\n",
    "scorers = [\n",
    "    {\n",
    "        \"name\": \"NLI_Baseline\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=False, use_mlm=False),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"STS_SENTENCE\",\n",
    "        \"model\": SummaCZS(sts_granularity=\"sentence\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=True, use_mlm=False),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STS_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(sts_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=True, use_mlm=False),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"MLM_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(mlm_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=False, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MLM_DOCUMENT\",\n",
    "        \"model\": SummaCZS(mlm_granularity=\"document\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=False, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"NLI_STS_SENTENCE\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", sts_granularity=\"sentence\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=True, use_mlm=False),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NLI_STS_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", sts_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=True, use_mlm=False),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"NLI_MLM_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", mlm_granularity=\"sentence\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=False, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NLI_MLM_DOCUMENT\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", mlm_granularity=\"document\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=False, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"STS_SENTENCE_MLM_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(sts_granularity=\"sentence\", mlm_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STS_SENTENCE_MLM_DOCUMENT\",\n",
    "        \"model\": SummaCZS(sts_granularity=\"sentence\", mlm_granularity=\"document\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"STS_PARAGRAPH_MLM_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(sts_granularity=\"paragraph\", mlm_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"STS_PARAGRAPH_MLM_DOCUMENT\",\n",
    "        \"model\": SummaCZS(sts_granularity=\"paragraph\", mlm_granularity=\"document\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=False, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"NLI_STS_SENTENCE_MLM_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", sts_granularity=\"sentence\", mlm_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NLI_STS_PARAGRAPH_MLM_PARAGRAPH\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", sts_granularity=\"paragraph\", mlm_granularity=\"paragraph\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NLI_STS_PARAGRAPH_MLM_DOCUMENT\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", sts_granularity=\"paragraph\", mlm_granularity=\"document\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"NLI_STS_SENTENCE_MLM_DOCUMENT\",\n",
    "        \"model\": SummaCZS(nli_granularity=\"sentence\", sts_granularity=\"sentence\", mlm_granularity=\"document\", model_name=\"vitc\", imager_load_cache=use_cache, use_nli=True, use_sts=True, use_mlm=True),\n",
    "        \"sign\": 1,\n",
    "    },\n",
    "]\n",
    "\n",
    "scorer_doc = ScorerWrapper(scorers, scoring_method=\"sum\", max_batch_size=50, use_caching=True)\n",
    "# scorer_para = ScorerWrapper([s for s in scorers if \"only_doc\" not in s], scoring_method=\"sum\", max_batch_size=50,\n",
    "#                           use_caching=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-08-01T16:49:53.191155Z",
     "start_time": "2023-08-01T16:49:30.058350100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= factcc ========\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c87d486b4d72490aba18952f6c95ea3f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/20 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f91e1dbfa0e4b6b84958dd2ebb037b1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from summac.utils_scorer import compute_paragraph_level\n",
    "from summac.run_baseline import compute_doc_level\n",
    "\n",
    "results = []\n",
    "for dataset in benchmark.datasets:\n",
    "\tif dataset[\"name\"] != \"factcc\":\n",
    "\t\tcontinue\n",
    "\tprint(\"======= %s ========\" % (dataset[\"name\"]))\n",
    "\tdatas = dataset[\"dataset\"][:20]\n",
    "\tcompute_doc_level(datas, scorer_doc)\n",
    "\tcompute_paragraph_level(scorer_para, datas)\n",
    "\n",
    "\tlabels = [d[\"label\"] for d in datas]\n",
    "\tpred_labels = [k for k in datas[0].keys() if \"pred_\" in k]\n",
    "\tfor pred_label in pred_labels:\n",
    "\t\tmodel_name, input_type = pred_label.replace(\"pred_\", \"\").split(\"|\")\n",
    "\t\tpreds = [d[pred_label] for d in datas]\n",
    "\t\tscores = [d[pred_label.replace(\"pred_\", \"\")] for d in datas]\n",
    "\t\tbalanced_acc = sklearn.metrics.balanced_accuracy_score(labels, preds)\n",
    "\t\troc_auc = sklearn.metrics.roc_auc_score(labels, scores)\n",
    "\n",
    "\t\tresults.append({\"model_name\": model_name, \"dataset_name\": dataset[\"name\"],\n",
    "\t\t\t\t\t\t\"input\": input_type, \"%s_bacc\" % (dataset[\"name\"]): balanced_acc,\n",
    "\t\t\t\t\t\t\"%s_roc_auc\" % (dataset[\"name\"]): roc_auc,\n",
    "\t\t\t\t\t\t\"labels\": labels, \"preds\": preds, \"scores\": scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'model_name': 'SummaC-ZS-VITC-L',\n  'dataset_name': 'factcc',\n  'input': 'doc',\n  'factcc_bacc': 0.84375,\n  'factcc_roc_auc': 0.90625,\n  'labels': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1],\n  'preds': [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n  'scores': [2.3758292198181152,\n   1.5491322070360183,\n   1.2231752618349023,\n   1.6722859978675841,\n   1.86775302445447,\n   1.6837735367672784,\n   1.696451097726822,\n   1.3572572556634743,\n   1.410097321909335,\n   1.5498905062675477,\n   1.2654736333272674,\n   1.512182655079024,\n   0.47850164620294455,\n   1.1098865903913975,\n   1.988972532749176,\n   1.4693138011627727,\n   1.598238244652748,\n   1.394063325598836,\n   1.4898820221424103,\n   1.7413866966962814]},\n {'model_name': 'total',\n  'dataset_name': 'factcc',\n  'input': 'doc',\n  'factcc_bacc': 0.84375,\n  'factcc_roc_auc': 0.90625,\n  'labels': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1],\n  'preds': [1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1],\n  'scores': [2.3758292198181152,\n   1.5491322070360183,\n   1.2231752618349023,\n   1.6722859978675841,\n   1.86775302445447,\n   1.6837735367672784,\n   1.696451097726822,\n   1.3572572556634743,\n   1.410097321909335,\n   1.5498905062675477,\n   1.2654736333272674,\n   1.512182655079024,\n   0.47850164620294455,\n   1.1098865903913975,\n   1.988972532749176,\n   1.4693138011627727,\n   1.598238244652748,\n   1.394063325598836,\n   1.4898820221424103,\n   1.7413866966962814]}]"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T16:49:53.244774600Z",
     "start_time": "2023-08-01T16:49:53.183645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed for caching\n",
    "# for scorer in scorers:\n",
    "# \tif \"SummaC\" in scorer[\"name\"]:\n",
    "# \t\tscorer[\"model\"].save_imager_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results.to_parquet('results.parquet.gzip', compression='gzip')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balanced accuracy score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f81e80c11c0>",
      "text/html": "<style type=\"text/css\">\n#T_c198a_row0_col0, #T_c198a_row0_col1 {\n  font-weight: bold;\n  background-color: #ebf3eb;\n  color: #000000;\n}\n</style>\n<table id=\"T_c198a\">\n  <caption>Balanced Accuracy</caption>\n  <thead>\n    <tr>\n      <th class=\"blank\" >&nbsp;</th>\n      <th class=\"blank level0\" >&nbsp;</th>\n      <th id=\"T_c198a_level0_col0\" class=\"col_heading level0 col0\" >factcc</th>\n      <th id=\"T_c198a_level0_col1\" class=\"col_heading level0 col1\" >overall</th>\n    </tr>\n    <tr>\n      <th class=\"index_name level0\" >model_name</th>\n      <th class=\"index_name level1\" >input</th>\n      <th class=\"blank col0\" >&nbsp;</th>\n      <th class=\"blank col1\" >&nbsp;</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th id=\"T_c198a_level0_row0\" class=\"row_heading level0 row0\" >SummaC-ZS-VITC-L</th>\n      <th id=\"T_c198a_level1_row0\" class=\"row_heading level1 row0\" >doc</th>\n      <td id=\"T_c198a_row0_col0\" class=\"data row0 col0\" >0.843750</td>\n      <td id=\"T_c198a_row0_col1\" class=\"data row0 col1\" >0.843750</td>\n    </tr>\n  </tbody>\n</table>\n"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "\n",
    "\n",
    "def highlight_max(data):\n",
    "\tis_max = data == data.max()\n",
    "\treturn ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = df.groupby([\"model_name\", \"input\"]).agg({\"%s_bacc\" % (d): \"mean\" for d in [\"factcc\"]})\n",
    "df.rename(columns={k: k.replace(\"_bacc\", \"\") for k in df.keys()}, inplace=True)\n",
    "df.drop(\"total\", inplace=True)\n",
    "# df[\"overall\"] = (df[\"factcc\"] + df[\"frank\"] + df[\"polytope\"] + df[\"cogensumm\"] + df[\"summeval\"] + df[\"xsumfaith\"]) / (\n",
    "# \t6.0)\n",
    "\n",
    "df[\"overall\"] = df[\"factcc\"]\n",
    "\n",
    "df.style.apply(highlight_max).background_gradient(cmap=cm, high=1.0, low=0.0).set_caption(\n",
    "\t\"Balanced Accuracy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T16:52:48.670847800Z",
     "start_time": "2023-08-01T16:52:48.649824Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-08-01T16:52:05.722953500Z",
     "start_time": "2023-08-01T16:52:05.309591600Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column(s) ['frank_bacc', 'polytope_bacc', 'summeval_bacc', 'xsumfaith_bacc'] do not exist\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 10\u001B[0m\n\u001B[1;32m      6\u001B[0m \t\u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfont-weight: bold\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m v \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m is_max]\n\u001B[1;32m      9\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(results)\n\u001B[0;32m---> 10\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgroupby\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel_name\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m_bacc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43md\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmean\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43md\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mxsumfaith\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpolytope\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfactcc\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msummeval\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mfrank\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     11\u001B[0m df\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{k: k\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_bacc\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m df\u001B[38;5;241m.\u001B[39mkeys()}, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     12\u001B[0m df\u001B[38;5;241m.\u001B[39mdrop(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtotal\u001B[39m\u001B[38;5;124m\"\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m/raid/AICOE/aviv/envs/lib/python3.8/site-packages/pandas/core/groupby/generic.py:1269\u001B[0m, in \u001B[0;36mDataFrameGroupBy.aggregate\u001B[0;34m(self, func, engine, engine_kwargs, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1266\u001B[0m func \u001B[38;5;241m=\u001B[39m maybe_mangle_lambdas(func)\n\u001B[1;32m   1268\u001B[0m op \u001B[38;5;241m=\u001B[39m GroupByApply(\u001B[38;5;28mself\u001B[39m, func, args, kwargs)\n\u001B[0;32m-> 1269\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_dict_like(func) \u001B[38;5;129;01mand\u001B[39;00m result \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1271\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m/raid/AICOE/aviv/envs/lib/python3.8/site-packages/pandas/core/apply.py:163\u001B[0m, in \u001B[0;36mApply.agg\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_str()\n\u001B[1;32m    162\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_dict_like(arg):\n\u001B[0;32m--> 163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43magg_dict_like\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    164\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m is_list_like(arg):\n\u001B[1;32m    165\u001B[0m     \u001B[38;5;66;03m# we require a list, but not a 'str'\u001B[39;00m\n\u001B[1;32m    166\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39magg_list_like()\n",
      "File \u001B[0;32m/raid/AICOE/aviv/envs/lib/python3.8/site-packages/pandas/core/apply.py:403\u001B[0m, in \u001B[0;36mApply.agg_dict_like\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    400\u001B[0m     selected_obj \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_selected_obj\n\u001B[1;32m    401\u001B[0m     selection \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_selection\n\u001B[0;32m--> 403\u001B[0m arg \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnormalize_dictlike_arg\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43magg\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mselected_obj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43marg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    405\u001B[0m is_groupby \u001B[38;5;241m=\u001B[39m \u001B[38;5;28misinstance\u001B[39m(obj, (DataFrameGroupBy, SeriesGroupBy))\n\u001B[1;32m    406\u001B[0m context_manager: ContextManager\n",
      "File \u001B[0;32m/raid/AICOE/aviv/envs/lib/python3.8/site-packages/pandas/core/apply.py:535\u001B[0m, in \u001B[0;36mApply.normalize_dictlike_arg\u001B[0;34m(self, how, obj, func)\u001B[0m\n\u001B[1;32m    533\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(cols) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    534\u001B[0m         cols_sorted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(safe_sort(\u001B[38;5;28mlist\u001B[39m(cols)))\n\u001B[0;32m--> 535\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mColumn(s) \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcols_sorted\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m do not exist\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    537\u001B[0m aggregator_types \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m, \u001B[38;5;28mdict\u001B[39m)\n\u001B[1;32m    539\u001B[0m \u001B[38;5;66;03m# if we have a dict of any non-scalars\u001B[39;00m\n\u001B[1;32m    540\u001B[0m \u001B[38;5;66;03m# eg. {'A' : ['mean']}, normalize all to\u001B[39;00m\n\u001B[1;32m    541\u001B[0m \u001B[38;5;66;03m# be list-likes\u001B[39;00m\n\u001B[1;32m    542\u001B[0m \u001B[38;5;66;03m# Cannot use func.values() because arg may be a Series\u001B[39;00m\n",
      "\u001B[0;31mKeyError\u001B[0m: \"Column(s) ['frank_bacc', 'polytope_bacc', 'summeval_bacc', 'xsumfaith_bacc'] do not exist\""
     ]
    }
   ],
   "source": [
    "cm = sns.light_palette(\"green\", as_cmap=True)\n",
    "\n",
    "\n",
    "def highlight_max(data):\n",
    "\tis_max = data == data.max()\n",
    "\treturn ['font-weight: bold' if v else '' for v in is_max]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df = df.groupby([\"model_name\", \"input\"]).agg({\"%s_bacc\" % (d): \"mean\" for d in [\"xsumfaith\", \"polytope\", \"factcc\", \"summeval\", \"frank\"]})\n",
    "df.rename(columns={k: k.replace(\"_bacc\", \"\") for k in df.keys()}, inplace=True)\n",
    "df.drop(\"total\", inplace=True)\n",
    "# df[\"overall\"] = (df[\"factcc\"] + df[\"frank\"] + df[\"polytope\"] + df[\"cogensumm\"] + df[\"summeval\"] + df[\"xsumfaith\"]) / (\n",
    "# \t6.0)\n",
    "\n",
    "df[\"overall\"] = (df[\"factcc\"] + df[\"frank\"] + df[\"polytope\"] + df[\"summeval\"] + df[\"xsumfaith\"]) / (\n",
    "\t5.0)\n",
    "\n",
    "df.style.apply(highlight_max).background_gradient(cmap=cm, high=1.0, low=0.0).set_precision(3).set_caption(\n",
    "\t\"Balanced Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "\n",
    "# # Analysis with confidence interval\n",
    "# strongest_baseline = {\"cogensumm\": \"DAE\", \"xsumfaith\": \"NER\", \"polytope\": \"QuestEval\", \"factcc\": \"DAE\",\n",
    "# \t\t\t\t\t  \"summeval\": \"QuestEval\", \"frank\": \"QuestEval\"}\n",
    "\n",
    "# P5 = 5 / 2  # Correction due to the fact that we are running 2 tests with the same data\n",
    "# P1 = 1 / 2  # Correction due to the fact that we are running 2 tests with the same data\n",
    "\n",
    "\n",
    "# def resample_balanced_acc(preds, labels, n_samples=100, sample_ratio=0.7):\n",
    "# \tN = len(preds)\n",
    "# \tidxs = list(range(N))\n",
    "# \tN_batch = int(sample_ratio * N)\n",
    "\n",
    "# \tbal_accs = []\n",
    "# \tfor _ in range(n_samples):\n",
    "# \t\trandom.shuffle(idxs)\n",
    "# \t\tbatch_preds = [preds[i] for i in idxs[:N_batch]]\n",
    "# \t\tbatch_labels = [labels[i] for i in idxs[:N_batch]]\n",
    "\n",
    "# \t\tbal_accs.append(sklearn.metrics.balanced_accuracy_score(batch_labels, batch_preds))\n",
    "# \treturn bal_accs\n",
    "\n",
    "\n",
    "# print(\"DATASET NAME\".ljust(15), \"MODEL NAME\".ljust(20))\n",
    "\n",
    "# sampled_batch_preds = {res[\"model_name\"]: [] for res in results}\n",
    "# for res in results:\n",
    "# \tif res[\"model_name\"] == \"total\":\n",
    "# \t\tprint(\"==================================================\")\n",
    "# \t\tcontinue\n",
    "\n",
    "# \tsamples = resample_balanced_acc(res[\"preds\"], res[\"labels\"])\n",
    "# \tsampled_batch_preds[res[\"model_name\"]].append(samples)\n",
    "# \tlow5, high5 = np.percentile(samples, P5), np.percentile(samples, 100 - P5)\n",
    "# \tlow1, high1 = np.percentile(samples, P1), np.percentile(samples, 100 - P1)\n",
    "# \tbacc = sklearn.metrics.balanced_accuracy_score(res[\"labels\"], res[\"preds\"])\n",
    "# \tif \"SummaC\" in res[\"model_name\"] or res[\"model_name\"] == strongest_baseline[res[\"dataset_name\"]]:\n",
    "\n",
    "# \t\tprint(res[\"dataset_name\"].ljust(15), res[\"model_name\"].ljust(20),\n",
    "# \t\t\t  \" - %.3f (%.3f - %.3f) (%.3f - %.3f)\" % (bacc, low5, high5, low1, high1))\n",
    "# \t\tif res[\"model_name\"] == strongest_baseline[res[\"dataset_name\"]]:\n",
    "# \t\t\tbl5, bh5, bl1, bh1 = low5, high5, low1, high1\n",
    "# \t\t\tprint(\"--------------\")\n",
    "# \t\telse:\n",
    "# \t\t\tif low5 >= bh5:\n",
    "# \t\t\t\tprint(\"Significant difference (p < 0.05)\")\n",
    "# \t\t\tif low1 >= bh1:\n",
    "# \t\t\t\tprint(\"Significant difference (p < 0.01)\")\n",
    "\n",
    "# print(\"==========================\")\n",
    "# print(\"==========================\")\n",
    "# print(\"==========================\")\n",
    "\n",
    "# # baseline = np.mean(np.array(sampled_batch_preds[\"QuestEval\"]), axis=0)\n",
    "# summaczs = np.mean(np.array(sampled_batch_preds[\"SummaC-ZS-VITC-L\"]), axis=0)\n",
    "# summacconv = np.mean(np.array(sampled_batch_preds[\"SummaC-Histo-VITC-L\"]), axis=0)\n",
    "\n",
    "# for model in [\"QuestEval\", \"SummaC-ZS-VITC-L\", \"SummaC-Histo-VITC-L\"]:\n",
    "# \tsamples = np.mean(np.array(sampled_batch_preds[model]), axis=0)\n",
    "# \tlow5, high5 = np.percentile(samples, P5), np.percentile(samples, 100 - P5)\n",
    "# \tlow1, high1 = np.percentile(samples, P1), np.percentile(samples, 100 - P1)\n",
    "\n",
    "# \tprint(\"OVERALL\".ljust(15), model.ljust(20), \" - (%.3f - %.3f) (%.3f - %.3f)\" % (low5, high5, low1, high1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df = df.groupby([\"model_name\", \"input\"]).agg({\"%s_roc_auc\" % (d): \"mean\" for d in [\"xsumfaith\", \"polytope\", \"factcc\", \"summeval\", \"frank\"]})\n",
    "df.rename(columns={k: k.replace(\"_roc_auc\", \"\") for k in df.keys()}, inplace=True)\n",
    "df.drop(\"total\", inplace=True)\n",
    "# df[\"overall\"] = (df[\"factcc\"] + df[\"frank\"] + df[\"polytope\"] + df[\"cogensumm\"] + df[\"summeval\"] + df[\"xsumfaith\"]) / (\n",
    "# \t6.0)\n",
    "\n",
    "df[\"overall\"] = (df[\"factcc\"] + df[\"frank\"] + df[\"polytope\"] + df[\"summeval\"] + df[\"xsumfaith\"]) / (\n",
    "\t5.0)\n",
    "\n",
    "df.style.apply(highlight_max).background_gradient(cmap=cm, high=1.0, low=0.0).set_precision(3).set_caption(\"ROC AUC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analysis with confidence interval\n",
    "# strongest_baseline = {\"cogensumm\": \"DAE\", \"xsumfaith\": \"QuestEval\", \"polytope\": \"QuestEval\", \"factcc\": \"DAE\",\n",
    "# \t\t\t\t\t  \"summeval\": \"QuestEval\", \"frank\": \"QuestEval\"}\n",
    "\n",
    "# P5 = 5 / 2  # Correction due to the fact that we are running 2 tests with the same data\n",
    "# P1 = 1 / 2  # Correction due to the fact that we are running 2 tests with the same data\n",
    "\n",
    "\n",
    "# def resample_roc_auc(scores, labels, n_samples=100, sample_ratio=0.7):\n",
    "# \tN = len(scores)\n",
    "# \tidxs = list(range(N))\n",
    "# \tN_batch = int(sample_ratio * N)\n",
    "\n",
    "# \troc_aucs = []\n",
    "# \tfor _ in range(n_samples):\n",
    "# \t\trandom.shuffle(idxs)\n",
    "# \t\tbatch_scores = [scores[i] for i in idxs[:N_batch]]\n",
    "# \t\tbatch_labels = [labels[i] for i in idxs[:N_batch]]\n",
    "# \t\troc_aucs.append(sklearn.metrics.roc_auc_score(batch_labels, batch_scores))\n",
    "# \treturn roc_aucs\n",
    "\n",
    "\n",
    "# sampled_batch_preds = {res[\"model_name\"]: [] for res in results}\n",
    "# print(\"DATASET NAME\".ljust(15), \"MODEL NAME\".ljust(20))\n",
    "# for res in results:\n",
    "# \tif res[\"model_name\"] == \"total\":\n",
    "# \t\tprint(\"==================================================\")\n",
    "# \t\tcontinue\n",
    "# \tsamples = resample_roc_auc(res[\"scores\"], res[\"labels\"])\n",
    "# \tsampled_batch_preds[res[\"model_name\"]].append(samples)\n",
    "# \tlow5, high5 = np.percentile(samples, P5), np.percentile(samples, 100 - P5)\n",
    "# \tlow1, high1 = np.percentile(samples, P1), np.percentile(samples, 100 - P1)\n",
    "# \troc_auc = sklearn.metrics.roc_auc_score(res[\"labels\"], res[\"scores\"])\n",
    "# \tif \"SummaC\" in res[\"model_name\"] or res[\"model_name\"] == strongest_baseline[res[\"dataset_name\"]]:\n",
    "# \t\tprint(res[\"dataset_name\"].ljust(15), res[\"model_name\"].ljust(20),\n",
    "# \t\t\t  \" - %.3f (%.3f - %.3f) (%.3f - %.3f)\" % (roc_auc, low5, high5, low1, high1))\n",
    "# \t\tif res[\"model_name\"] == strongest_baseline[res[\"dataset_name\"]]:\n",
    "# \t\t\tbl5, bh5, bl1, bh1 = low5, high5, low1, high1\n",
    "# \t\t\tprint(\"--------------\")\n",
    "# \t\telse:\n",
    "# \t\t\tif low5 >= bh5:\n",
    "# \t\t\t\tprint(\"Significant difference (p < 0.05)\")\n",
    "# \t\t\tif low1 >= bh1:\n",
    "# \t\t\t\tprint(\"Significant difference (p < 0.01)\")\n",
    "\n",
    "# print(\"==========================\")\n",
    "# print(\"==========================\")\n",
    "# print(\"==========================\")\n",
    "\n",
    "# baseline = np.mean(np.array(sampled_batch_preds[\"QuestEval\"]), axis=0)\n",
    "# summaczs = np.mean(np.array(sampled_batch_preds[\"SummaC-ZS-VITC-L\"]), axis=0)\n",
    "# summacconv = np.mean(np.array(sampled_batch_preds[\"SummaC-Histo-VITC-L\"]), axis=0)\n",
    "\n",
    "# for model in [\"QuestEval\", \"SummaC-ZS-VITC-L\", \"SummaC-Histo-VITC-L\"]:\n",
    "# \tsamples = np.mean(np.array(sampled_batch_preds[model]), axis=0)\n",
    "# \tlow5, high5 = np.percentile(samples, P5), np.percentile(samples, 100 - P5)\n",
    "# \tlow1, high1 = np.percentile(samples, P1), np.percentile(samples, 100 - P1)\n",
    "\n",
    "# \tprint(\"OVERALL\".ljust(15), model.ljust(20), \" - (%.3f - %.3f) (%.3f - %.3f)\" % (low5, high5, low1, high1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T06:09:36.891509800Z",
     "start_time": "2023-08-01T06:09:36.883512300Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "finalized": {
   "timestamp": 1625710190289,
   "trusted": true
  },
  "interpreter": {
   "hash": "c723e9d1a9662a11de23e7914e75631adbad784f516bc181f2c98a6790ee4bb2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
